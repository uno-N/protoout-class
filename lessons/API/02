# 2. Webブラウザでセンシング・ボイスコントロール

本章では、Webブラウザに組み込まれている`ブラウザAPI`を使って、位置情報を取得したり、音声認識を行います。  
完璧に理解する必要はありません。コピペでも良いので動かせるようになることが大切です。

また、ブラウザAPIは、位置情報APIや音声認識APIの他にもたくさんの種類があります。  
授業で扱っていないブラウザAPIを探し、動かしてみましょう。

## 2-1. ブラウザAPIとWeb API

[第2回の授業](https://github.com/protoout/moicen-teaching-materials/blob/master/lesson02/handson02.md#3-api%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%83%87%E3%83%BC%E3%82%BF%E3%82%92%E5%8F%96%E5%BE%97%E3%81%97%E3%81%A6%E3%81%BF%E3%82%88%E3%81%86)で`Web API`を扱いましたが、`ブラウザAPI`とは特徴が異なります。

家で料理する場合で例えると、食材をどこから取ってくるかが変わります。

[![Image from Gyazo](https://i.gyazo.com/f6a7a4c89f0058720bb8172806cf59c7.png)](https://gyazo.com/f6a7a4c89f0058720bb8172806cf59c7)

> `ブラウザAPI`を使うと、パソコンやスマートフォンの情報(=冷蔵庫にある食材)を取ってくることができます。
>
> 一方で、天気やビールの情報を取得することはできません。  
> これらは`Web API`(=配達)で取り寄せるようにしましょう。

情報を取得するケースを説明しましたが、ブラウザAPIでは他にも、音声認識APIやVR/AR用のAPIなどの様々な用途のAPIが用意されています。  
https://developer.mozilla.org/ja/docs/Web/API

本日の授業では、`ブラウザAPI`にフォーカスします。

最初に、いくつかのブラウザAPIをピックアップして実際に動くコードと一緒に紹介します。  
演習では、授業では扱っていないブラウザAPIを探し、動かすことにチャレンジしましょう。

## 2-2. スマートフォンでセンシング - Sensor API

現行の多くのスマートフォンのブラウザでは、「位置情報」と「加速度」をWebアプリで取り扱うことが可能です。  
これはすなわち **スマホをセンシング機器として活用できる** ことにつながります。  
実際に試してみましょう！

ここから先の手順では、ブラウザの実験的な機能を利用しています。  
ブラウザによっては動かないことがあります。Google Chrome を使ってアクセスしましょう。  

### 2-2-1. 試してみよう

1. CodePenのサンプルペン「[スマホセンサを試してみる](https://codepen.io/tmitsuoka0423/pen/zYwBwaq)」にアクセスしてください。
2. アクセスしてしばらく経つと「位置情報を許可しますか？」のダイアログが出るので許可をクリックしてください。
3. 加速度は表示されないが、位置情報だけ出てくる、という感じになるかと思います。  
  位置情報の「Google Mapsで確認」をクリックして、ブラウザで認識されている現在地を確認してみましょう。  
  [![Image from Gyazo](https://i.gyazo.com/caf45b200faa70b41850a75a5c8ccd7f.png)](https://gyazo.com/caf45b200faa70b41850a75a5c8ccd7f)
4. 次に、スマートフォンなどのモバイル端末で同じページを表示してみましょう。  
  [![Image from Gyazo](https://i.gyazo.com/abe20dce43d4ae67f5f271c7ade87b90.png)](https://gyazo.com/abe20dce43d4ae67f5f271c7ade87b90)  
   - URL: https://sensor-henna.vercel.app/  
   - アクセス後、位置情報利用ダイアログが出たら許可をクリックしておきましょう。
5. まず加速度を試してみましょう。  
   - `取得開始` ボタンをクリックし、加速度情報の取得を開始します。
   - その後スマートフォンを動かし、X,Y,Zそれぞれの値が変化することを確認します。  
6. 次にスマートフォンを机の上に置き、すべての加速度が安定していることを確認したうえで、机を軽く叩いてみましょう。かなり敏感に加速度が検知されていることがわかるかと思います。
7. 最後に位置情報の「Google Mapsで確認」をクリックし、現在地を再度確認してみてください。
   - 最近のスマートフォンには全てGPSが搭載されており、そこからの位置情報を利用しているため、デスクトップPC環境と比較してかなり高精度で位置が検出されていることがわかるかと思います。  
<a href="https://gyazo.com/f758aac98955c6d2d8eb96ae5f008fa1"><img src="https://i.gyazo.com/f758aac98955c6d2d8eb96ae5f008fa1.png" alt="Image from Gyazo" width="300"/></a>

加速度と位置情報なら、スマホで簡単取得してすぐにWebアプリで使えちゃいます！  
ぜひ活用してみてください。

### 2-2-2. 参考

[位置情報 API - Web API | MDN](https://developer.mozilla.org/ja/docs/Web/API/Geolocation_API)

## 2-3. ボイスコントロール - Web Speech API

近年のスマートスピーカーやスマートアシスタントに代表される、音声の認識・発話を行うことができるWeb標準の技術です。  
これらが使えるようになると以下のメリットがあります。

- 音声認識
  - ボイスコマンドを使った操作ができる
  - テキストへの文字起こし・音声データではなくテキストデータとしての保存（→軽量なデータにできる）
  - リアルタイム翻訳
  - 入力UI設計の省略
- 音声発話
  - ボイスフィードバック（任意の情報を好きなだけ喋らせられる）
  - 視覚障害者向けサポート
  - 朗読コンテンツの作成

### 2-3-1. まずは試してみよう

音声認識と発話ができるCodePenサンプルです。  
[音声認識 & 発話 with Vue\.js](https://codepen.io/ukkz/pen/xxqzQwP)

zoomのほうはミュートにしたままでいいので、以下を試してみましょう。

1. `スタート` ボタンをクリックして何かしゃべり、認識されて文字として反映されることを確認する。
2. 発話させる の下の入力欄に何か文字列を入れ、 `しゃべって！` ボタンクリックで発話されることを確認する。

### 2-3-2. ボイスコマンドをつくってみよう

音声認識側を少し触ってみましょう。認識されたときに実行される部分を簡単に解説します。

- 特定の言葉を認識したときに何かしらのアクションが実施されるようにJSを書き換えてみましょう。
- 自分専用のボイスコマンドを作ってみましょう。

アクション例:

- 「OK、グーグル」→ `alert('いいえ、私はアレクサです');`
- 「ホームページをひらいて」→ `window.location.href = 'https://yahoo.co.jp/';`

### 2-3-3. 参考

[Web Speech APIを使う - Web API | MDN](https://developer.mozilla.org/ja/docs/Web/API/Web_Speech_API/Using_the_Web_Speech_API)

先進的な機能ではあるものの「Experimental」であり、利用可能なブラウザが限られていることに気をつけてください。

### 2-3-4. ブラウザAPIの探し方、使い方

1. 下記ページをざっと眺めて、面白そうなAPIを見つけます。
   - [Web API リファレンス | MDN](https://developer.mozilla.org/ja/docs/orphaned/Web/Reference/API)
   - [Web APIs | MDN](https://developer.mozilla.org/en-US/docs/Web/API)
   - [Experiments with Google](https://experiments.withgoogle.com/)
1. 公式リファレンスを探します。わかりやすい場合、そのまま読み進めます。
1. そうでない場合、QiitaやGitHub、Google検索で、APIの概要や使い方を紹介している記事、サンプルコードを探します。  
1. 良い情報が見つからない場合、覚悟して公式リファレンスを読みます。

---

- [前ページに戻る](./handson01.md)
- [次ページに進む](./handson03.md)
- [目次に戻る](.)
