# Face APIを使ってクラウドAIに触れてみる

## 1. この章のゴール

- クラウドで推論できるAzure Face APIを使ってみる
- パラメーターを変えて、いろんな属性を取得してみる

## 2. Azure Face API

### 2.1. ざっくりAzure

[![Image from Gyazo](https://i.gyazo.com/9928745dd7b6ad0bde8d5f7cc66ea875.png)](https://gyazo.com/9928745dd7b6ad0bde8d5f7cc66ea875)

- Microsoftが提供しているクラウドコンピューティングサービスのこと
- 200以上のサービスが提供されている
- AI・機械学習系のサービスも充実している

### 2.2. ざっくりAzure Face API

機能は大きく分けて2つです。

- 顔検出
  - > 画像内の各顔の27のランドマークを含む、ポーズ、顔の覆い、顔の毛などの属性とともに、1つ以上の人間の顔を検出します。  
    > <a href="https://gyazo.com/96883a0d6cec3835d1dd226f2787122f"><img src="https://i.gyazo.com/96883a0d6cec3835d1dd226f2787122f.png" alt="Image from Gyazo" width="500"/></a>

- 顔認証
  - > 2つの顔が同一人物のものである可能性を検証し、信頼度スコアを取得します。  
    > <a href="https://gyazo.com/96b1abceff69a646c7db2de6bc5fb21d"><img src="https://i.gyazo.com/96b1abceff69a646c7db2de6bc5fb21d.png" alt="Image from Gyazo" width="500"/></a>

## 3. 顔検出してみよう

Face API実際に使ってみましょう。

### 事前準備

1. 下記資料を参考に`キー`と`エンドポイント`を発行し、メモ帳などにコピーしておきます。
   - [Face APIを使ってみよう](https://zenn.dev/tmitsuoka0423/books/b21e50db77ff1eab89a3/viewer/chapter3#2.3.1.face-apiを使ってみよう)

### プログラム

1. 好きな場所に`face-api`フォルダーを作成し、VS Codeで開きます。
    - 以下の作業はすべて、`face-api`フォルダーで行います。
1. VS Codeでターミナルを開き、以下のコマンドを実行します。
    ```
    npm init -y
    npm i @azure/cognitiveservices-face @azure/ms-rest-azure-js
    ```
1. `index.js`ファイルを作成します。
1. 以下のコードをコピペし、保存します。
    ```javascript
    "use strict";

    // インストールしたライブラリを読み込む
    const { FaceClient } = require("@azure/cognitiveservices-face");
    const { CognitiveServicesCredentials } = require("@azure/ms-rest-azure-js");

    // Azure Face APIを使うための準備
    const faceKey = "事前準備のキーをここに貼り付ける";
    const faceEndPoint = "事前準備のエンドポイントをここに貼り付ける";
    const cognitiveServiceCredentials = new CognitiveServicesCredentials(faceKey);
    const faceClient = new FaceClient(cognitiveServiceCredentials, faceEndPoint);

    const main = async () => {
      // Azure Face APIに画像を送り、結果を受け取る
      // 画像URLは好きなものに変更してください
      const result = await faceClient.face.detectWithUrl("https://prtimes.jp/i/79105/1/resize/d79105-1-505527-7.jpg", {
        returnFaceAttributes: ["smile", "makeup"], // ここにカンマ(,)区切りでパラメータを追加する
      });

      // resultに結果が入ってきます
      console.log(result);
      console.log(result[0].faceAttributes.makeup.eyeMakeup);
    };

    main();
    ```

    - TIPS
      - JSONの扱い方は下記記事を参考にしましょう。
      - [PUNK APIでクラフトビールの情報を取得しながらAPI利用を学ぶ🍻](https://zenn.dev/n0bisuke/articles/02-punkapi-node-api-learn#%E3%83%93%E3%83%BC%E3%83%AB%E3%81%AE%E5%90%8D%E5%89%8D%E3%81%A8%E7%94%BB%E5%83%8F%E3%81%A0%E3%81%91%E6%AC%B2%E3%81%97%E3%81%84)
    - NOTE
      - :warning:キーとエンドポイントは公開しないようにしてください。:warning:
1. ターミナルで`node index.js`を実行します。
1. こんな感じの結果が表示されればOK。顔が検出され、位置が表示されています。
    ```js
    [
      {
        faceId: '17cb701e-71fa-46a7-aa59-c4f62d6ed631',
        recognitionModel: 'recognition_01',
        faceRectangle: { width: 81, height: 81, left: 139, top: 130 }, // <-- 顔の位置
        faceAttributes: { smile: 1, makeup: [Object] } // <-- パラメータに指定した情報
      }
    ]
    false // <-- result[0].faceAttributes.makeup.eyeMakeupの値
    ```

## 4. (演習)Azure Face APIで他の情報を取得してみよう(10分)

1. パラメーターを変更して、メガネを掛けているかどうか判定してみましょう。
    - `faceAttributes`に`glasses`を追加して、実行しましょう。
2. 他にも判定できる項目がたくさんありますので、試してみましょう。
    - 各項目の詳細はこちらをご確認ください。
      - [顔検出と顔属性の概念 - Azure Cognitive Services | Microsoft Docs](https://docs.microsoft.com/ja-jp/azure/cognitive-services/face/concepts/face-detection#attributes)
    - 設定できる項目一覧。`returnFaceAttributes`にカンマ区切りで追加しましょう。
      - アクセサリ: `accessories`
      - 年齢: `age`
      - ぼかし: `blur`
      - 感情: `emotion`
      - 露出: `exposure`
      - 顔ひげ: `facialHair`
      - 性別: `gender`
      - 眼鏡: `glasses`
      - 髪の毛: `hair`
      - 頭部姿勢: `headPose`
      - 化粧: `makeup`
      - ノイズ: `noise`
      - オクルージョン: `occlusion`
      - 笑顔: `smile`

## 5. 参考

- [画像分析AIを使ったLINE Botを1時間で作ってみよう（顔検出編）～プロトアウト体験会～](https://zenn.dev/tmitsuoka0423/books/b21e50db77ff1eab89a3)

---

## 目次へ

[目次](https://github.com/protoout/po-common/tree/main/lessons)に戻ります
