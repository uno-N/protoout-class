# Hugging Face Inference API

Hugging Face上に保存されているAIモデルを実際にローカルに落として利用しようとすることは、非常にハードルが高いです。モデルの多くは`Python`の`Pytorch`というライブラリで学習されており

- Pythonの環境が必要
- Pytorchの知識が必要
- Macの場合、PytorchのGPU処理が安定しない（最近対応したばかり）

などのハードルがあるため、初学者が活用することは現実的ではありません。  
それを可能とするのが`Inference API`となります

<a href="https://huggingface.co/inference-api">
  <img src="https://i.gyazo.com/f2f51eba8064430ddfb3769596f3cd06.png">
</a>

Inference APIを使用することで、Hugging faceのクラウド上でモデルを利用した画像や文章の生成を実行することができるため、Hugging Faceにアップロードされているモデルを活用するための敷居を大きく下げることができます。

---

<!-- ![image](https://i.gyazo.com/f31ff971e297dbba19fcb90466495401.png)

まずは話を聞くタイムです。 -->

## 1. inference API 使用準備

### 1-1. Hugging Faceへの登録

Hugging Faceに登録していない方は登録してログインしましょう。下記画像のような画面になるかと思います。

![image](https://i.gyazo.com/28503613a6db88a7a248e9caef233a91.png)

### 1-2. Access Tokenの発行

ご自身のアイコンをクリックし、`Settings`へ移動。`Access Tokens`をクリックします。

![image](https://i.gyazo.com/e3cce8b2e6191fcc5c67080e3561c9ef.png)

アクセストークンを発行します。Nameは好みのお名前で、Roleは`Read`で問題ありません。

![image](https://i.gyazo.com/0f32daad141d6ac300c8b291c0bc9631.png)

以上でAPIの使用準備は完了です。

## 2. inference API の実行

## 2-1. サンプルコード

[トップページ](https://huggingface.co/inference-api)にPython向けのサンプルコードは記載がありますが、これをJavaScript向けに改変し、`Stable diffusion`を叩くためのコードを記載します。**実行したフォルダーと同じ場所に画像が保存されれば成功です。**

```js
const axios = require('axios');
const dotenv = require('dotenv');
const fs = require('fs');
dotenv.config();

const query = async (model, data) => {
    const res = await axios.post(
        `https://api-inference.huggingface.co/models/${model}`, // models以下に利用するAIモデルを記載
        JSON.stringify(data),
        {
            headers: { Authorization: `Bearer ${process.env.API_TOKEN} || '手打ち'` }, //API_TOKENを直接または.envに記載
            responseType: 'arraybuffer'
        }
    );
    const result = await res.data;
    return result;
}

const model = 'stabilityai/stable-diffusion-2-1' // 利用するAIモデルを記載
const prompt = "blue hair girl" // Stable-diffusionに渡すプロンプト

query(model, prompt).then((res) => {
    fs.writeFileSync(`${prompt}.jpg`, res, 'binary'); // 生成した画像をjpgとして保存
});
```

このコードをそのまま実行すると、`const model = 'stabilityai/stable-diffusion-2-1'`にて指定されているstable diffusion-2-1をAPI経由で実行できます。

### 2-2. モデルの選び方

実際のモデルのページに記載がある名前をコピーペーストして、上記コードの文字列部分を変更しましょう。名前横のアイコンを押下することでコピー可能です。

![image](https://i.gyazo.com/0b850aef69e7d17c0cd561e70572ec0f.png)

モデルはメニューバーのModelsより選択しましょう。`GitHub`や`npm`と考え方は同じです

![image](https://i.gyazo.com/1a64fc5068ccfb4845a6cc747107f69b.png)

### 2-3. モデルごとの注意点

上記コードは画像を保存するためのコードとなっていますが、実行するAIモデルによって出力される形式が異なります。**形式と目的に応じたコードの改変は随時実行してください**。

## 3. Huggingface.js

### 3-1. Huggingface.jsについて

<a href="https://huggingface.co/docs/huggingface.js/index">
  <img src="https://i.gyazo.com/340471b609b042c03d747573f68b2007.png">
</a>

上記ページより閲覧できます。  
先ほどまでの`Inference API`をよりJavaScript, TypeScriptにとって使いやすく改変したものとなります。とくに`TypeScript`を使用する際には相性が良いという記載がありますので、皆さまこちらを使用されることが良いかと思います

### 3-2. サンプルコード

同じくstable diffusion2.1を叩きます  
まず、`@huggingface/inference`のインストールが必要です

```bash
npm install @huggingface/inference
```

次にNode.js（version 18以上）で次のコードを実行してみましょう。**実行したフォルダーと同じ場所に画像が保存されれば成功です。**

```js
const fs = require('fs')
const hugging = require('@huggingface/inference');
const dotenv = require('dotenv');
dotenv.config();

const hf = new hugging.HfInference(process.env.API_TOKEN || '手打ち');

const main = async (model, prompt, nPrompt) => {
  const res = await hf.textToImage({
    inputs: prompt,
    model: model,
    parameters: {
      negative_prompt: nPrompt,
    }
  });
  const buffer = Buffer.from(await res.arrayBuffer());
  fs.writeFileSync('image.jpg', buffer);
}

const model = 'stabilityai/stable-diffusion-2' // モデル
const prompt = 'award winning high resolution photo of a giant tortoise/((ladybird)) hybrid, [trending on artstation]'; //プロンプト
const nPrompt = 'blurry' //ネガティブプロンプト

main(model, prompt, nPrompt);
```

main()関数の中に記載があるように、この場合`hf.textToImage`を実行しており、テキストから画像を生成するということがわかりやすいコードとなっており、データ処理もやりやすいです。JavaScriptやTypeScriptで実行する場合は、こちらを利用しましょう。
その他のHugginface.jsのコードもリンク先にありますので、必要に応じて使用しましょう。

---

このページの内容は以上です。  
**[目次](./readme.md)** に戻り、全体構成を確認してから講師の指示にしたがって進めましょう。
